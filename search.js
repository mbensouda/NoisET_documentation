window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "noisets.noisettes", "modulename": "noisets.noisettes", "type": "module", "doc": "<h1 id=\"noisetsupsup-noise-sampling-learning-expansion-detection-of-t-cell-receptors-using-bayesian-inference\">NoisET<sup>*</sup>  NOIse sampling learning &amp; Expansion detection of T-cell receptors using Bayesian inference.</h1>\n\n<p>High-throughput sequencing of T- and B-cell receptors makes it possible to track immune\nrepertoires across time, in different tissues, in acute and chronic diseases or in healthy individuals. However\nquantitative comparison between repertoires is confounded by variability in the read count of each receptor\nclonotype due to sampling, library preparation, and expression noise. We present an easy-to-use python\npackage NoisET that implements and generalizes a previously developed Bayesian method in <a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007873&amp;rev=2\">Puelma Touzel et al, 2020</a>. It can be used\nto learn experimental noise models for repertoire sequencing from replicates, and to detect responding\nclones following a stimulus. The package was tested on different repertoire sequencing technologies and\ndatasets. NoisET package is desribed <a href=\"https://arxiv.org/abs/2102.03568\">here</a>. </p>\n\n<p><sup>* NoisET should be pronounced as \"noisettes\" (ie hazelnuts in French).</sup></p>\n\n<p>Functions library for NoisET - construction of noisettes package\nCopyright (C) 2021 Meriem Bensouda Koraichi. \n   This program is free software: you can redistribute it and/or modify\n    it under the terms of the GNU General Public License as published by\n    the Free Software Foundation, either version 3 of the License, or\n    (at your option) any later version.\n    This program is distributed in the hope that it will be useful,\n    but WITHOUT ANY WARRANTY; without even the implied warranty of\n    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n    GNU General Public License for more details.\n    You should have received a copy of the GNU General Public License\n    along with this program.  If not, see <a href=\"https://www.gnu.org/licenses/\">https://www.gnu.org/licenses/</a>.</p>\n\n<h1 id=\"installation\">Installation</h1>\n\n<p>Python 3 </p>\n\n<p>NoisET is a python /3.6 software. It is available on PyPI and can be downloaded and installed through pip:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>pip install noisets\n</code></pre></div>\n\n<p>Watch out, Data pre-processing, diversity estimates and generation of neutral TCR clonal dynamics is not possible yet with installation with pip. Use only the sudo command below.</p>\n\n<p>To install NoisET and try the tutorial dusplayed in this github: gitclone the file in your working environment. \nUsing the terminal, go to NoisET directory and write the following command : </p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>sudo python setup.py install\n</code></pre></div>\n\n<p>If you do not have the following python libraries (that are useful to use NoisET) : numpy, pandas, matplotlib, seaborn, scipy, scikit-learn, please do the following commands, to try first to install the dependencies separately: :</p>\n\n<pre><code>python -m pip install -U pip\npython -m pip install -U matplotlib\npip install numpy\npip install pandas\npip install matplotlib\npip install seaborn\npip install -U scikit-learn\n\n</code></pre>\n\n<h1 id=\"documentation\">Documentation</h1>\n\n<h2 id=\"command-lines-with-terminal\">Command lines with terminal</h2>\n\n<p>A tutorial is available at <a href=\"https://github.com/mbensouda/NoisET_tutorial\">https://github.com/mbensouda/NoisET_tutorial</a> . \nThree commands are available to use :</p>\n\n<ul>\n<li><code>noiset-noise</code> To infer Null noise model: NoisET first function (1)</li>\n<li><code>noiset-nullgenerator</code> To qualitatively check consistency of NoisET first function</li>\n<li><code>noiset-detection</code> To detect responding clones to a stimulus: NoisET second function (2)</li>\n</ul>\n\n<p>All options are described typing one of the previous commands + <code>--help</code>or <code>-h</code>. Options are also described in the following READme.</p>\n\n<h2 id=\"1-infer-noise-model\">1/ Infer noise model</h2>\n\n<p>To infer null noise model: NoisET first function (1), use the command <code>noiset-noise</code></p>\n\n<p>At the command prompt, type:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>noiset-noise --path <span class=\"s1\">&#39;DATA_REPO/&#39;</span> --f1 <span class=\"s1\">&#39;FILENAME1_X_REP1&#39;</span> --f2 <span class=\"s1\">&#39;FILENAME2_X_REP2&#39;</span> --<span class=\"o\">(</span>noisemodel<span class=\"o\">)</span>\n</code></pre></div>\n\n<p>Several options are needed to learn noise model from two replicate samples associated to one individual at a specific time point:</p>\n\n<h4 id=\"1-data-information\">1/ Data information:</h4>\n\n<ul>\n<li><code>--path 'PATHTODATA'</code>: set path to data file </li>\n<li><code>--f1 'FILENAME1_X_REP1'</code>: filename for individual X replicate 1 </li>\n<li><code>--f2 'FILENAME2_X_REP2'</code>: filename for individual X replicate 2 </li>\n</ul>\n\n<p>If your TCR CDR3 clonal populations features (ie clonal fractions, clonal counts, clonal nucleotide CDR3 sequences and clonal amino acid sequences) have different column names than: ('Clone fraction', 'Clone count', 'N. Seq. CDR3', 'AA. Seq. CDR3), you can specify the name directly by using: </p>\n\n<ul>\n<li><code>--specify</code> </li>\n<li><code>--freq 'frequency'</code> : Column label associated to clonal fraction </li>\n<li><code>--counts 'counts'</code>:  Column label associated to clonal count  </li>\n<li><code>--ntCDR3 'ntCDR3'</code>:  Column label associated to clonal CDR3 nucleotides sequence  </li>\n<li><code>--AACDR3 'AACDR3'</code>:  Column label associated to clonal CDR3 amino acid sequence</li>\n</ul>\n\n<h4 id=\"2-choice-of-noise-model-parameters-meaning-described-in-methods-section\">2/ Choice of noise model: (parameters meaning described in Methods section)</h4>\n\n<ul>\n<li><code>--NBPoisson</code>: Negative Binomial + Poisson Noise Model - 5 parameters </li>\n<li><code>--NB</code>: Negative Binomial - 4 parameters  </li>\n<li><code>--Poisson</code>: Poisson - 2 parameters </li>\n</ul>\n\n<h4 id=\"3-example\">3/ Example:</h4>\n\n<p>At the command prompt, type:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>noiset-noise --path <span class=\"s1\">&#39;data_examples/&#39;</span> --f1 <span class=\"s1\">&#39;Q1_0_F1_.txt.gz&#39;</span> --f2 <span class=\"s1\">&#39;Q1_0_F2_.txt.gz&#39;</span> --NB\n</code></pre></div>\n\n<p>This command line will learn four parameters associated to negative binomial null noise Model <code>--NB</code> for individual Q1 at day 0.\nA '.txt' file is created in the working directory: it is a 5/4/2 parameters data-set regarding on NBP/NB/Poisson noise model. In this example, it is a four parameters table (already created in data_examples repository). \nYou can run previous examples using data (Q1 day 0/ day15) provided in the data_examples folder - data from <a href=\"https://www.pnas.org/content/115/50/12704\">Precise tracking of vaccine-responding T cell clones reveals convergent and personalized response in identical twins, Pogorelyy et al, PNAS</a> </p>\n\n<h4 id=\"4-example-with-specify\">4/ Example with <code>--specify</code>:</h4>\n\n<p>At the command prompt, type:</p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>noiset-noise --path <span class=\"s1\">&#39;data_examples/&#39;</span> --f1 <span class=\"s1\">&#39;replicate_1_1.tsv.gz&#39;</span> --f2 <span class=\"s1\">&#39;replicate_1_2.tsv.gz&#39;</span> --specify --freq <span class=\"s1\">&#39;frequencyCount&#39;</span> --counts <span class=\"s1\">&#39;count&#39;</span> --ntCDR3 <span class=\"s1\">&#39;nucleotide&#39;</span> --AACDR3 <span class=\"s1\">&#39;aminoAcid&#39;</span> --NB\n</code></pre></div>\n\n<p>As previously this command enables us to learn four parameters associated to negative binomial null noise model <code>--NB</code> for one individual in cohort produced in <a href=\"https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0213684\">Model to improve specificity for identification of clinically-relevant expanded T cells in peripheral blood, Rytlewski et al, PLOS ONE</a>. </p>\n\n<h2 id=\"2-generate-synthetic-data-from-null-model-learning\">2/ Generate synthetic data from null model learning:</h2>\n\n<p>To qualitatively check consistency of NoisET first function (1) with experiments or for other reasons, it can be useful to generates synthetic replicates from the null model (described in Methods section).\nOne can also generalte healthy RepSeq samples dynamics using the noise model which has been learned in a first step anf giving the time-scale dynamics of turnover of the repertoire as defined in <a href=\"https://www.biorxiv.org/content/10.1101/2022.05.01.490247v1\">https://www.biorxiv.org/content/10.1101/2022.05.01.490247v1</a>. Check <a href=\"https://github.com/statbiophys/NoisET/blob/master/NoisET%20example%20-%20Null%20model%20learning%20.ipynb\">here</a>.  </p>\n\n<p>To generate synthetic TCR RepSeq data replicates having chosen sampling noise characteristics, use the command <code>noiset-nullgenerator</code>\n <div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>noiset-nullgenerator --<span class=\"o\">(</span>noise-model<span class=\"o\">)</span> --nullpara <span class=\"s1\">&#39;NULLPARAS&#39;</span> --NreadsI float --NreadsII float --Nclones float --output <span class=\"s1\">&#39;SYNTHETICDATA&#39;</span> <br />\n </code></pre></div></p>\n\n<h4 id=\"1-choice-of-noise-model\">1/ Choice of noise model:</h4>\n\n<p>The user must chose one of the three possible models for the probability that a TCR has <strong> an empirical count n </strong> knowing that its  <strong> true frequency is f </strong>, P(n|f): a Poisson distribution <code>--Poisson</code>, a negative binomial distribution <code>--NB</code>, or a two-step model combining Negative-Binomial and a Poisson distribution <code>--NBP</code>. n is the empirical clone size and  depends on the experimental protocol.\nFor each P(n|f), a set of parameters is learned.</p>\n\n<ul>\n<li><code>--NBPoisson</code>: Negative Binomial + Poisson Noise Model - 5 parameters 5 parameters described in <a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007873&amp;rev=2\">Puelma Touzel et al, 2020</a>: power-law exponent of clonotypes frequencies distributions <code>'alph_rho'</code>, minimum of clonotype frequencies distribution <code>'fmin'</code>, <code>'beta'</code> and <code>'alpha'</code>, parameters of negative binomial distribution constraining mean and variance of P(m|f) distribution (m being the number of cells associated to a clonotype in the experiemental sample), and <code>'m_total'</code> the total number of cells in the sample of interest..</li>\n<li><code>--NB</code>: Negative Binomial - 4 parameters: power-law of the clonotypes frequencies distributions (same ansatz than in <a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007873&amp;rev=2\">Puelma Touzel et al, 2020</a> <code>'alph_rho'</code>, minimum of clonotype frequencies distribution <code>'fmin'</code>, <code>'beta'</code> and <code>'alpha'</code>, parameters of negative binomial distribution constraining mean and variance of P(n|f) distribution. <em> NB(fNreads, fNreads + betafNreads<sup>alpha</sup>) </em>. (Nreads is the total number of reads in the sample of interest.) </li>\n<li><code>--Poisson</code>: Poisson - 2 parameters power-law of the clonotypes frequencies distributions (same ansatz than in <a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007873&amp;rev=2\">Puelma Touzel et al, 2020</a><code>'alph_rho'</code> and minimum of clonotype frequencies distribution <code>'fmin'</code>. P(n|f) is a Poisson distribution of parameter <em> fNreads </em>. (Nreads is the total number of reads in the sample of interest.)</li>\n</ul>\n\n<h4 id=\"2-specify-learned-noise-parameters\">2/ Specify learned noise parameters:</h4>\n\n<ul>\n<li><code>--nullpara 'PATHTOFOLDER/NULLPARAS.txt'</code>: parameters learned thanks to NoisET function (1) !!! Make sure to match correctly the noise model and the null parameter file content : 5 parameters for <code>--NBP</code>, 4 parameters for <code>--NB</code>and 2 parameters\nfor <code>--Poisson</code>. </li>\n</ul>\n\n<h4 id=\"3-sequencing-properties-of-data\">3/ Sequencing properties of data:</h4>\n\n<ul>\n<li><code>--NreadsI NNNN</code>: total number  of reads in first replicate - it should match the actual data. In the example below, it is the sum of 'Clone count' in 'Q1_0_F1_.txt.gz'. </li>\n<li><code>--Nreads2 NNNN</code>: total number  of reads in second replicate - it should match the actual data. In the example below, it is the sum of 'Clone count' in 'Q1_0_F2_.txt.gz'. </li>\n<li><code>--Nclones NNNN</code>: total number of clones in union of two replicates - it should match the actual data. In the example below, it is the number of clones present in both replicates : 'Q1_0_F1_.txt.gz' and 'Q1_0_F2_.txt.gz'.</li>\n</ul>\n\n<h4 id=\"4-output-file\">4/ Output file</h4>\n\n<p><code>--output 'SYNTHETICDATA'</code>: name of the output file where you can find the synthetic data set. </p>\n\n<p>At the command prompt, type \n <div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>noiset-nullgenerator --NB --nullpara <span class=\"s1\">&#39;data_examples/nullpara1.txt&#39;</span> --NreadsI <span class=\"m\">829578</span> --NreadsII <span class=\"m\">954389</span> --Nclones <span class=\"m\">776247</span> --output <span class=\"s1\">&#39;test&#39;</span> <br />\n </code></pre></div></p>\n\n<p>Running this line, you create a 'synthetic_test.csv' file with four columns : 'Clone_count_1', 'Clone_count_2', 'Clone_fraction_1', 'Clone_fraction_2', resctively synthetic read counts and frequencies that you would have found in an experimental sample of same learned parameters 'nullpara1.txt', 'NreadsI', 'NreadsII' and 'Nclones'.</p>\n\n<h2 id=\"3-detect-responding-clones\">3/ Detect responding clones:</h2>\n\n<p>Detects responding clones to a stimulus: NoisET second function (2)</p>\n\n<p>To detect responding clones from two RepSeq data at time_1 and time_2, use the command <code>noiset-detection</code></p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>noiset-detection --<span class=\"o\">(</span>noisemodel<span class=\"o\">)</span>  --nullpara1 <span class=\"s1\">&#39;FILEFORPARAS1&#39;</span> --nullpara2 <span class=\"s1\">&#39;FILEFORPARAS1&#39;</span> --path <span class=\"s1\">&#39;REPO/&#39;</span> --f1 <span class=\"s1\">&#39;FILENAME_TIME_1&#39;</span> --f2 <span class=\"s1\">&#39;FILENAME_TIME_2&#39;</span> --pval float --smedthresh float --output <span class=\"s1\">&#39;DETECTIONDATA&#39;</span> \n</code></pre></div>\n\n<p>Several options are needed to learn noise model from two replicate samples associated to one individual at a specific time point:</p>\n\n<h4 id=\"1-choice-of-noise-model-2\">1/ Choice of noise model:</h4>\n\n<ul>\n<li><code>--NBPoisson</code>: Negative Binomial + Poisson Noise Model - 5 parameters </li>\n<li><code>--NB</code>: Negative Binomial - 4 parameters  </li>\n<li><code>--Poisson</code>: Poisson - 2 parameters </li>\n</ul>\n\n<h4 id=\"2-specify-learned-parameters-for-both-time-points\">2/ Specify learned parameters for both time points:</h4>\n\n<p>(they can be the same for both time points if replicates are not available but to use carefully as mentioned in [ARTICLE]) </p>\n\n<ul>\n<li><code>--nullpara1 'PATH/FOLDER/NULLPARAS1.txt'</code>: parameters learned thanks to NoisET function (1) for time 1 </li>\n<li><code>--nullpara2 'PATH/FOLDER/NULLPARAS2.txt'</code>: parameters learned thanks to NoisET function (1) for time 2  </li>\n</ul>\n\n<p>!!! Make sure to match correctly the noise model and the null parameters file content : 5 parameters for <code>--NBP</code>, 4 parameters for <code>--NB</code>and 2 parameters\nfor <code>--Poisson</code>. </p>\n\n<h4 id=\"3-data-information\">3/ Data information:</h4>\n\n<ul>\n<li><code>--path 'PATHTODATA'</code>: set path to data file </li>\n<li><code>--f1 'FILENAME1_X_time1'</code>: filename for individual X time 1 </li>\n<li><code>--f2 'FILENAME2_X_time2'</code>: filename for individual X time 2 </li>\n</ul>\n\n<p>If your TCR CDR3 clonal populations features (ie clonal fractions, clonal counts, clonal nucleotides CDR3 sequences and clonal amino acids sequences) have different column names than: ('Clone fraction', 'Clone count', 'N. Seq. CDR3', 'AA. Seq. CDR3), you can specify the name by using: </p>\n\n<ul>\n<li><code>--specify</code> </li>\n<li><code>--freq 'frequency'</code> : Column label associated to clonal fraction </li>\n<li><code>--counts 'counts'</code>:  Column label associated to clonal count  </li>\n<li><code>--ntCDR3 'ntCDR3'</code>:  Column label associated to clonal CDR3 nucleotides sequence  </li>\n<li><code>--AACDR3 'AACDR3'</code>:  Column label associated to clonal CDR3 amino acid sequence</li>\n</ul>\n\n<h4 id=\"4-detection-thresholds-more-details-in-methods-section\">4/ Detection thresholds: (More details in Methods section).</h4>\n\n<ul>\n<li><code>--pval XXX</code> : p-value threshold for the expansion/contraction - use 0.05 as a default value. </li>\n<li><code>--smedthresh XXX</code> : log fold change median threshold for the expansion/contraction - use 0 as a default value. </li>\n</ul>\n\n<h4 id=\"5-output-file\">5/ Output file</h4>\n\n<p><code>--output 'DETECTIONDATA'</code>: name of the output file (.csv) where you can find a list of the putative responding clones with statistics features. (More details in Methods section).</p>\n\n<p>At the command prompt, type </p>\n\n<div class=\"pdoc-code codehilite\"><pre><span></span><code><span class=\"gp\">$ </span>noiset-detection --NB  --nullpara1 <span class=\"s1\">&#39;data_examples/nullpara1.txt&#39;</span> --nullpara2 <span class=\"s1\">&#39;data_examples/nullpara1.txt&#39;</span> --path <span class=\"s1\">&#39;data_examples/&#39;</span> --f1 <span class=\"s1\">&#39;Q1_0_F1_.txt.gz&#39;</span> --f2 <span class=\"s1\">&#39;Q1_15_F1_.txt.gz&#39;</span> --pval <span class=\"m\">0</span>.05 --smedthresh <span class=\"m\">0</span> --output <span class=\"s1\">&#39;detection&#39;</span> \n</code></pre></div>\n\n<p>Ouput: table containing all putative detected clones with statistics features about logfold-change variable <em> s </em>: more theoretical description <a href=\"https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007873&amp;rev=2\">Puelma Touzel et al, 2020</a>.</p>\n\n<h2 id=\"python-package\">Python package</h2>\n"}, {"fullname": "noisets.noisettes.longitudinal_analysis", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis", "type": "class", "doc": "<p>A class used to represent longitudinal RepSeq data and pre-analysis of the longitudinal data associated with\none individual.</p>\n\n<p>...</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>patient</strong> (str):\nthe patient label associated with the data</li>\n<li><strong>data_foler</strong> (str):\nthe name of the animal</li>\n<li><strong>replicate_1D</strong> (str):\nthe default first replicate label is '_F1' but can be modified by the user to match the used data</li>\n<li><strong>replicate_2D</strong> (str):\nthe default first replicate label is '_F2' but can be modified by the user to match the used data</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>import_clones()\n    to import all the clonotypes of a given patient and store them in a dictionary.\n    It returns also the list of #ordered time points of the longitudinal dataset.</p>\n\n<p>merge_replicates(ntCDR3 = 'N. Seq. CDR3')\n    tool to merge biological replicate 1 and biological replicate 2 data</p>\n\n<p>persistence_clones(ntCDR3 = 'N. Seq. CDR3')\n    TODESCRIBE</p>\n\n<p>plot_hist_persistence(filename,  ntCDR3 = 'N. Seq. CDR3', fontsize = 12)\n    TODESCRIBE</p>\n\n<p>get_top_clones_set(n_top_clones, ntCDR3 = 'N. Seq. CDR3', clone_count = 'Clone count')\n    TODESCRIBE</p>\n\n<p>build_traj_frame(top_clones_set, ntCDR3 = 'N. Seq. CDR3', clone_count = 'Clone count')\n    TODESCRIBE</p>\n\n<p>plot_trajectories(n_top_clones, filename, colormap = 'viridis', ntCDR3 = 'N. Seq. CDR3', clone_count = 'Clone count')\n    TODESCRIBE</p>\n\n<p>PCA_traj(n_top_clones, ntCDR3 = 'N. Seq. CDR3', clone_count = 'Clone count', nclus = 3)\n    TODESCRIBE</p>\n\n<p>plot_clusters2D(n_top_clones, filename, ntCDR3 = 'N. Seq. CDR3', clone_count = 'Clone count', nclus = 3, colormap = 'viridis')\n    TODESCRIBE</p>\n\n<p>plot_traj_clusters(n_top_clones, filename, ntCDR3 = 'N. Seq. CDR3', clone_count = 'Clone count', nclus = 3, colormap = 'viridis')\n    TODESCRIBE</p>\n"}, {"fullname": "noisets.noisettes.longitudinal_analysis.__init__", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">patient</span>, </span><span class=\"param\"><span class=\"n\">data_folder</span>, </span><span class=\"param\"><span class=\"n\">replicate_1_ID</span><span class=\"o\">=</span><span class=\"s1\">&#39;_F1&#39;</span>, </span><span class=\"param\"><span class=\"n\">replicate_2_ID</span><span class=\"o\">=</span><span class=\"s1\">&#39;_F2&#39;</span></span>)</span>"}, {"fullname": "noisets.noisettes.longitudinal_analysis.import_clones", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.import_clones", "type": "function", "doc": "<p>to import all the clonotypes of a given patient and store them in a dictionary.\nIt returns also the list of #ordered time points of the longitudinal dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>patient</strong> (str):\nThe ID of the patient</li>\n<li><strong>data_folder</strong> (str):\nThe name of the folder to find data</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>clones</strong>: a dictionary of data_frames giving all the samples of the patient.</li>\n<li><strong>times</strong>: a numpy vector containing all the RepSeq sampling times ordered.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.merge_replicates", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.merge_replicates", "type": "function", "doc": "<p>Creating the dataframes for the merged replicates. After this operation the \nclones_merged dictionary contains the the merged table of the first and second\nreplicate. The indexes are the same as before without the F1/2 label.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>ntCDR3</strong> (str):\nThe label of the TCR nucleotide sequences columns, the default value is 'N. Seq. CDR3'.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>clones_merged</strong>: a dictionary of data_frames giving all the samples of the patient that were merged for both replicates.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.persistence_clones", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.persistence_clones", "type": "function", "doc": "<p>A list of all the clonotypes appearing in all the time points is created.\nNote that if one clonotype is present in 2 or more points, it will be repeated\ntwice in the list.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>ntCDR3</strong> (str):\nThe label of the TCR nucleotide sequences columns, the default value is 'N. Seq. CDR3'.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>unique_clones</strong>: a dictionary of data_frames giving all the samples of the patient that were merged for both replicates.</li>\n<li><strong>time_occurence</strong></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.plot_hist_persistence", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.plot_hist_persistence", "type": "function", "doc": "<p>TOFILL</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>filename</strong> (str):\nTOFILL</li>\n<li><strong>ntCDR3</strong> (str):\nThe label of the TCR nucleotide sequences columns, the default value is 'N. Seq. CDR3'.</li>\n<li><strong>fontsize</strong> (float):\nTOFILL</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>plot</strong>: TO DESCRIBE</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">filename</span>, </span><span class=\"param\"><span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span>, </span><span class=\"param\"><span class=\"n\">fontsize</span><span class=\"o\">=</span><span class=\"mi\">12</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.get_top_clones_set", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.get_top_clones_set", "type": "function", "doc": "<p>TOFILL</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>filename</strong> (str):\nTOFILL</li>\n<li><strong>ntCDR3</strong> (str):\nThe label of the TCR nucleotide sequences columns, the default value is 'N. Seq. CDR3'.</li>\n<li><strong>fontsize</strong> (float):\nTOFILL</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>plot</strong>: TO DESCRIBE</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">n_top_clones</span>, </span><span class=\"param\"><span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span>, </span><span class=\"param\"><span class=\"n\">clone_count</span><span class=\"o\">=</span><span class=\"s1\">&#39;Clone count&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.build_traj_frame", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.build_traj_frame", "type": "function", "doc": "<p>This builds a dataframe containing the count at all the time points for each \nof the clonotypes specified in top_clones_set.\nThe dataframe has also a field that contains the cumulative count.\nThe trajectory dataframe is initialised with indexes as the clonotypes in\ntop_clones_set</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>top_clones_set</strong> (TOFILL):\nTOFILL</li>\n<li><strong>ntCDR3</strong> (str):\nThe label of the TCR nucleotide sequences columns, the default value is 'N. Seq. CDR3'.</li>\n<li><strong>clone_count</strong> (str):\nTOFILL</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>traj_frame</strong>: TO DESCRIBE</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">top_clones_set</span>,</span><span class=\"param\">\t<span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">clone_count</span><span class=\"o\">=</span><span class=\"s1\">&#39;Clone count&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.plot_trajectories", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.plot_trajectories", "type": "function", "doc": "<p>Function to plot the trajectories of the first top n clones using your favorite colormap</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n_top_clones</strong> (TOFILL):\nTOFILL</li>\n<li><strong>filename</strong> (str):\nTOFILL</li>\n<li><strong>colormap</strong> (TOFILL):\nTOFILL, default one</li>\n<li><strong>ntCDR3</strong> (str):\nTOFILL, default one</li>\n<li><strong>clone_count</strong> (str):\nTOFILL, default one</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>plot</strong>: TO DESCRIBE</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">n_top_clones</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span>,</span><span class=\"param\">\t<span class=\"n\">colormap</span><span class=\"o\">=</span><span class=\"s1\">&#39;viridis&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">clone_count</span><span class=\"o\">=</span><span class=\"s1\">&#39;Clone count&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.PCA_traj", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.PCA_traj", "type": "function", "doc": "<p>Perform PCA computation over the normalized trajectories of n_top_clones TCR clones\nnclus: number of clusters of clonal dynamics, by default this number is set to 3</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n_top_clones</strong> (TOFILL):\nTOFILL</li>\n<li><strong>ntCDR3</strong> (str):\nTOFILL, default one</li>\n<li><strong>clone_count</strong> (str):\nTOFILL, default one</li>\n<li><strong>nclus</strong> (float):\nTOFILL</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>pca</strong>: TO DESCRIBE</li>\n<li><strong>clustering</strong></li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">n_top_clones</span>,</span><span class=\"param\">\t<span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">clone_count</span><span class=\"o\">=</span><span class=\"s1\">&#39;Clone count&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">nclus</span><span class=\"o\">=</span><span class=\"mi\">3</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.plot_clusters2D", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.plot_clusters2D", "type": "function", "doc": "<p>TOFILL</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n_top_clones</strong> (TOFILL):\nTOFILL</li>\n<li><strong>filename</strong> (str):\nTOFILL</li>\n<li><strong>ntCDR3</strong> (str):\nTOFILL, default one</li>\n<li><strong>clone_count</strong> (str):\nTOFILL, default one</li>\n<li><strong>nclus</strong> (float):\nTOFILL</li>\n<li><strong>colormap</strong> (str):\nTOFILL</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>plot</strong>: TO DESCRIBE</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">n_top_clones</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span>,</span><span class=\"param\">\t<span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">clone_count</span><span class=\"o\">=</span><span class=\"s1\">&#39;Clone count&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">nclus</span><span class=\"o\">=</span><span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">colormap</span><span class=\"o\">=</span><span class=\"s1\">&#39;viridis&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.longitudinal_analysis.plot_traj_clusters", "modulename": "noisets.noisettes", "qualname": "longitudinal_analysis.plot_traj_clusters", "type": "function", "doc": "<p>TOFILL</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>n_top_clones</strong> (TOFILL):\nTOFILL</li>\n<li><strong>filename</strong> (str):\nTOFILL</li>\n<li><strong>ntCDR3</strong> (str):\nTOFILL, default one</li>\n<li><strong>clone_count</strong> (str):\nTOFILL, default one</li>\n<li><strong>nclus</strong> (float):\nTOFILL</li>\n<li><strong>colormap</strong> (str):\nTOFILL</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>plot</strong>: TO DESCRIBE</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">n_top_clones</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span>,</span><span class=\"param\">\t<span class=\"n\">ntCDR3</span><span class=\"o\">=</span><span class=\"s1\">&#39;N. Seq. CDR3&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">clone_count</span><span class=\"o\">=</span><span class=\"s1\">&#39;Clone count&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">nclus</span><span class=\"o\">=</span><span class=\"mi\">3</span>,</span><span class=\"param\">\t<span class=\"n\">colormap</span><span class=\"o\">=</span><span class=\"s1\">&#39;viridis&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Data_Process", "modulename": "noisets.noisettes", "qualname": "Data_Process", "type": "class", "doc": "<h2 id=\"todo-in-the-future-merge-this-class-with-other-classes\">TODO in the future, merge this class with other classes.</h2>\n\n<p>A class used to represent longitudinal RepSeq data and pre-analysis of the longitudinal data associated with\none individual.</p>\n\n<p>...</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>path</strong> (str):\nthe name of the path to get access to the data files to use for our analysis</li>\n<li><strong>filename1</strong> (str):\nthe name of the file of the RepSeq sample which can be the first replicate when deciphering the experimental noise \nor the first time point RepSeq sample when analysing responding clones to a stimulus between two time points.</li>\n<li><strong>filename2</strong> (str):\nthe name of the file of the RepSeq sample which can be the second replicate when deciphering the experimental noise \nor the second time point RepSeq sample when analysing responding clones to a stimulus between two time points.</li>\n<li><strong>colnames1</strong> (str):\nlist of columns names of data-set - first sample</li>\n<li><strong>colnames2</strong> (str):\nlist of columns names of data-set - second sample</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>import_data() : \n    to import and merged two RepSeq samples and build a unique data-frame with frequencies and abundances of all TCR clones present in the \n    union of both samples.</p>\n"}, {"fullname": "noisets.noisettes.Data_Process.__init__", "modulename": "noisets.noisettes", "qualname": "Data_Process.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span>, </span><span class=\"param\"><span class=\"n\">filename1</span>, </span><span class=\"param\"><span class=\"n\">filename2</span>, </span><span class=\"param\"><span class=\"n\">colnames1</span>, </span><span class=\"param\"><span class=\"n\">colnames2</span></span>)</span>"}, {"fullname": "noisets.noisettes.Data_Process.import_data", "modulename": "noisets.noisettes", "qualname": "Data_Process.import_data", "type": "function", "doc": "<p>TOFILL</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>NONE</strong></li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>number_clones</strong>: numpy array, number of clones in the data frame which is the union of the two RepSeq used as entries of the function</li>\n<li><strong>df</strong>: pandas data-frame which is the data-frame containing the informations labeled in colnames vector string\nfor both RepSeq samples taken as input.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Noise_Model", "modulename": "noisets.noisettes", "qualname": "Noise_Model", "type": "class", "doc": "<p>A class used to build an object associated to methods in order to learn the experimental noise from same day \nbiological RepSeq samples.</p>\n\n<p>...</p>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>get_sparserep(df) :\n    get sparse representation of the abundances / frequencies of the TCR clones present in both RepSeq samples of interest.\n    this changes the data input to fasten the algorithm</p>\n\n<p>learn_null_model(df, noise_model, init_paras,  output_dir = None, filename = None, display_loss_function = False) :\n    function to optimize the likelihood associated to the experimental noise model and get the associated parameters.</p>\n\n<p>diversity_estimate(df, paras, noise_model) :\n    function to get the estimation of diversity from the noise model information.</p>\n"}, {"fullname": "noisets.noisettes.Noise_Model.__init__", "modulename": "noisets.noisettes", "qualname": "Noise_Model.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">()</span>"}, {"fullname": "noisets.noisettes.Noise_Model.get_sparserep", "modulename": "noisets.noisettes", "qualname": "Noise_Model.get_sparserep", "type": "function", "doc": "<p>Tranforms {(n1,n2)} data stored in pandas dataframe to a sparse 1D representation.\nunicountvals_1(2) are the unique values of n1(2).\nsparse_rep_counts gives the counts of unique pairs.\nndn1(2) is the index of unicountvals_1(2) giving the value of n1(2) in that unique pair.\nlen(indn1)=len(indn2)=len(sparse_rep_counts)</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas data frame):\ndata-frame which is the output of the method .import_data() for one Data_Process instance.\nthese data-frame should give the list of TCR clones present in two replicates RepSeq samples\nassociated to their clone frequencies and clone abundances in the first and second replicate.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>indn1</strong>: numpy array list of indexes of all values of unicountvals_1</li>\n<li><strong>indn2</strong>: numpy array list of indexes of all values of unicountvals_2</li>\n<li><strong>sparse_rep_counts</strong>: numpy array, # of clones having the read counts pair {(n1,n2)}</li>\n<li><strong>unicountvals_1</strong>: numpy array list of unique counts values present in the first sample in df[clone_count_1]</li>\n<li><strong>unicountvals_2</strong>: numpy array list of unique counts values present in the second sample in df[clone_count_2]</li>\n<li><strong>Nreads1</strong>: float, total number of counts/reads in the first sample referred in df by \"_1\"</li>\n<li><strong>Nreads2</strong>: float, total number of counts/reads in the second sample referred in df by \"_2\"</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">df</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Noise_Model.learn_null_model", "modulename": "noisets.noisettes", "qualname": "Noise_Model.learn_null_model", "type": "function", "doc": "<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas data frame):\ndata-frame which is the output of the method .import_data() for one Data_Process instance.\nthese data-frame should give the list of TCR clones present in two replicates RepSeq samples\nassociated to their clone frequencies and clone abundances in the first and second replicate.</li>\n<li><strong>noise_model</strong> (numpy array):\nchoice of noise model</li>\n<li><strong>init_paras</strong> (numpy array):\ninitial vector of parameters to start the optimization of the model from data (df)</li>\n<li><strong>output_dir</strong> (str):\ndefault value is None, it is the output directory name i which we want to save the values of the parameters</li>\n<li><strong>display_loss_function</strong> (bool):\nboolean variable to chose if we want to print the loss function during the experimental noise learning, default value is \nNone.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>outstruct</strong>: numpy array parameters of the noise model</li>\n<li><strong>constr_value</strong>: float, value of the constraint</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">df</span>,</span><span class=\"param\">\t<span class=\"n\">noise_model</span>,</span><span class=\"param\">\t<span class=\"n\">init_paras</span>,</span><span class=\"param\">\t<span class=\"n\">output_dir</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">display_loss_function</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Noise_Model.diversity_estimate", "modulename": "noisets.noisettes", "qualname": "Noise_Model.diversity_estimate", "type": "function", "doc": "<p>Estimate diversity of the individual repertoire from the experimental noise learning step. </p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (data-frame):\nThe data-frame which has been used to learn the noise model</li>\n<li><strong>paras</strong> (numpy array):\nvector containing the noise parameters</li>\n<li><strong>noise_model</strong> (int):\nchoice of noise model</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>diversity_estimate</strong>: float, diversity estimate from the noise model inference.</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">df</span>, </span><span class=\"param\"><span class=\"n\">paras</span>, </span><span class=\"param\"><span class=\"n\">noise_model</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Expansion_Model", "modulename": "noisets.noisettes", "qualname": "Expansion_Model", "type": "class", "doc": "<p>A class used to build an object associated to methods in order to select significant expanding or \ncontracting clones from RepSeq samples taken at two different time points.</p>\n\n<p>...</p>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>get_sparserep(df) :\n    get sparse representation of the abundances / frequencies of the TCR clones present in RepSeq samples of both time points.\n    This changes the data input to fasten the algorithm</p>\n\n<p>expansion_table(outpath, paras_1, paras_2, df, noise_model, pval_threshold, smed_threshold):\n    generate the table of clones that have been significantly detected to be responsive to an acute stimuli.</p>\n"}, {"fullname": "noisets.noisettes.Expansion_Model.__init__", "modulename": "noisets.noisettes", "qualname": "Expansion_Model.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">()</span>"}, {"fullname": "noisets.noisettes.Expansion_Model.get_sparserep", "modulename": "noisets.noisettes", "qualname": "Expansion_Model.get_sparserep", "type": "function", "doc": "<p>Tranforms {(n1,n2)} data stored in pandas dataframe to a sparse 1D representation.\nunicountvals_1(2) are the unique values of n1(2).\nsparse_rep_counts gives the counts of unique pairs.\nndn1(2) is the index of unicountvals_1(2) giving the value of n1(2) in that unique pair.\nlen(indn1)=len(indn2)=len(sparse_rep_counts)</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas data frame):\ndata-frame which is the output of the method .import_data() for one Data_Process instance.\nthese data-frame should give the list of TCR clones present in two RepSeq samples, talen at two \ndifferent time points, associated to their clone frequencies and clone abundances in the first and second replicate?</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>indn1</strong>: numpy array list of indexes of all values of unicountvals_1</li>\n<li><strong>indn2</strong>: numpy array list of indexes of all values of unicountvals_2</li>\n<li><strong>sparse_rep_counts</strong>: numpy array, # of clones having the read counts pair {(n1,n2)}</li>\n<li><strong>unicountvals_1</strong>: numpy array list of unique counts values present in the first sample in df[clone_count_1]</li>\n<li><strong>unicountvals_2</strong>: numpy array list of unique counts values present in the second sample in df[clone_count_2]</li>\n<li><strong>Nreads1</strong>: float, total number of counts/reads in the first sample referred in df by \"_1\" for first time point</li>\n<li><strong>Nreads2</strong>: float, total number of counts/reads in the second sample referred in df by \"_2\" for second time point</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">df</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Expansion_Model.expansion_table", "modulename": "noisets.noisettes", "qualname": "Expansion_Model.expansion_table", "type": "function", "doc": "<p>generate the table of clones that have been significantly detected to be responsive to an acute stimuli.    </p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>outpath</strong> (str):\nName of the directory where to store the output table</li>\n<li><strong>paras_1</strong> (numpy array):\nparameters of the noise model that has been learned at time_1</li>\n<li><strong>paras_2</strong> (numpy array):\nparameters of the noise model that has been learned at time_2</li>\n<li><strong>df</strong> (pandas dataframe):\npandas dataframe merging the two RepSeq data at time_1 and time_2</li>\n<li><strong>noise_model</strong> (int):\nchoice of noise model 0: Poisson, 1: negative Binomial, 2: negative Binomial + Poisson</li>\n<li><strong>pval_threshold</strong> (float):\nP-value threshold to detect and discriminate if a TCR clone has expanded</li>\n<li><strong>smed_threshold</strong> (float):\nmedian of the log-fold change threshold to detect if a TCR clone has expanded</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>data-frame - csv file</strong>: the output is a csv file of columns : $s_{1-low}$, $s_{2-med}$, $s_{3-high}$, $s_{max}$, $\bar{s}$, $f_1$, $f_2$, $n_1$, $n_2$, 'CDR3_nt', 'CDR3_AA' and '$p$-value'</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">outpath</span>,</span><span class=\"param\">\t<span class=\"n\">paras_1</span>,</span><span class=\"param\">\t<span class=\"n\">paras_2</span>,</span><span class=\"param\">\t<span class=\"n\">df</span>,</span><span class=\"param\">\t<span class=\"n\">noise_model</span>,</span><span class=\"param\">\t<span class=\"n\">pval_threshold</span>,</span><span class=\"param\">\t<span class=\"n\">smed_threshold</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Generator", "modulename": "noisets.noisettes", "qualname": "Generator", "type": "class", "doc": "<p>A class used to build an object to generate in-Silico (synthetic) RepSeq samples, in the case of replicates at\nthe same day and in the case of having 2 samples generated at an initial time for the first one and some time after (months, years)\nfor the second one using the geometric Brownian motion model decribed in <a href=\"https://www.biorxiv.org/content/10.1101/2022.05.01.490247v1\">https://www.biorxiv.org/content/10.1101/2022.05.01.490247v1</a>.</p>\n\n<p>...</p>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>gen_synthetic_data_Null(paras, noise_model, NreadsI,NreadsII,Nsamp):\n    generate in-silico same day RepSeq replicates.</p>\n\n<p>generate_trajectories(tau, theta, method, paras_1, paras_2, t_ime, filename, NreadsI = '1e6', NreadsII = '1e6'):\n    generate in-silico t_ime apart RepSeq samples.</p>\n"}, {"fullname": "noisets.noisettes.Generator.__init__", "modulename": "noisets.noisettes", "qualname": "Generator.__init__", "type": "function", "doc": "<p></p>\n", "signature": "<span class=\"signature pdoc-code condensed\">()</span>"}, {"fullname": "noisets.noisettes.Generator.gen_synthetic_data_Null", "modulename": "noisets.noisettes", "qualname": "Generator.gen_synthetic_data_Null", "type": "function", "doc": "<p>outputs an array of observed clone frequencies and corresponding dataframe of pair counts\nfor a null model learned from a dataset pair with NreadsI and NreadsII number of reads, respectively.\nCrucial for RAM efficiency, sampling is conditioned on being observed in each of the three (n,0), (0,n'), and n,n'>0 conditions\nso that only Nsamp clones need to be sampled, rather than the N clones in the repertoire.\nNote that no explicit normalization is applied. It is assumed that the values in paras are consistent with N<f>=1 \n(e.g. were obtained through the learning done in this package).</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">paras</span>, </span><span class=\"param\"><span class=\"n\">noise_model</span>, </span><span class=\"param\"><span class=\"n\">NreadsI</span>, </span><span class=\"param\"><span class=\"n\">NreadsII</span>, </span><span class=\"param\"><span class=\"n\">Nsamp</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "noisets.noisettes.Generator.generate_trajectories", "modulename": "noisets.noisettes", "qualname": "Generator.generate_trajectories", "type": "function", "doc": "<p>generate in-silico t_ime apart RepSeq samples.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>paras_1</strong> (numpy array):\nparameters of the noise model that has been learnt at time_1</li>\n<li><strong>paras_2</strong> (numpy array):\nparameters of the noise model that has been learnt at time_2</li>\n<li><strong>method</strong> (str):\n'negative_binomial' or 'poisson'</li>\n<li><strong>tau</strong> (float):\nfirst time-scale parameter of the dynamics</li>\n<li><strong>theta</strong> (float):\nsecond time-scale parameter of the dynamics</li>\n<li><strong>t_ime</strong> (float):\nnumber of years between both synthetic sampling (between time_1 and time_2)</li>\n<li><strong>filename</strong> (str):\nname of the file in which the dataframe is stored</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>data-frame - csv file</strong>: the output is a csv file of columns : 'Clone_count_1' (at time_1) 'Clone_count_2' (at time_2) and the frequency counterparts 'Clone_frequency_1' and 'Clone_frequency_2'</li>\n</ul>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">tau</span>,</span><span class=\"param\">\t<span class=\"n\">theta</span>,</span><span class=\"param\">\t<span class=\"n\">method</span>,</span><span class=\"param\">\t<span class=\"n\">paras_1</span>,</span><span class=\"param\">\t<span class=\"n\">paras_2</span>,</span><span class=\"param\">\t<span class=\"n\">t_ime</span>,</span><span class=\"param\">\t<span class=\"n\">filename</span>,</span><span class=\"param\">\t<span class=\"n\">NreadsI</span><span class=\"o\">=</span><span class=\"s1\">&#39;1e6&#39;</span>,</span><span class=\"param\">\t<span class=\"n\">NreadsII</span><span class=\"o\">=</span><span class=\"s1\">&#39;1e6&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();